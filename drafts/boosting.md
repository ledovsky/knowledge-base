# Notes on Boosting methods

## Theory reference

* E. Sokolov. Lecture Notes from MSU ML course on Ensemble Methods, RU. [1](https://github.com/esokolov/ml-course-msu/blob/master/ML15-spring/lecture-notes/Sem02_ensembles.pdf), [2](https://github.com/esokolov/ml-course-msu/blob/master/ML15-spring/lecture-notes/Sem03_ensembles.pdf), [3](https://github.com/esokolov/ml-course-msu/blob/master/ML15-spring/lecture-notes/Sem04_ensembles.pdf), [4](https://github.com/esokolov/ml-course-msu/blob/master/ML15-spring/lecture-notes/Sem05_ensembles.pdf)
* [Awesome XGBoost](https://github.com/dmlc/xgboost/tree/master/demo)
* [Тонкости оптимизации xgboost](https://www.kaggle.com/c/santander-customer-satisfaction/forums/t/20662/overtuning-hyper-parameters-especially-re-xgboost/118487#post118487)
